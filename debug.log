load_ssl_context verify=True cert=None trust_env=True http2=False
load_verify_locations cafile='/Users/sameerhumagain/Sam Projects/opensupport/support/venv/lib/python3.9/site-packages/certifi/cacert.pem'
Not Found: /
Not Found: /
Not Found: /
Not Found: /
Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-9782ea06-a53b-4cac-b221-75b6b61fa33c', 'json_data': {'messages': [{'role': 'user', 'content': 'Hi'}, {'role': 'user', 'content': 'Hi'}], 'model': 'gpt-3.5-turbo', 'max_tokens': 150, 'n': 1, 'response_format': {}, 'stop': None, 'temperature': 0.7}}
Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0xffff97c86a10>
start_tls.started ssl_context=<ssl.SSLContext object at 0xffff97e0cdd0> server_hostname='api.openai.com' timeout=5.0
start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0xffff97c91f50>
send_request_headers.started request=<Request [b'POST']>
send_request_headers.complete
send_request_body.started request=<Request [b'POST']>
send_request_body.complete
receive_response_headers.started request=<Request [b'POST']>
receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Sat, 03 May 2025 02:53:32 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'337'), (b'Connection', b'keep-alive'), (b'vary', b'Origin'), (b'x-request-id', b'req_9e25847724492041bd686514945f4ee4'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=.FGNEKtXkb4Yl4RfVVHPpsYUpdjM3scYdl3fqGLlR0I-1746240812-1.0.1.1-Ymeu_8fVYDIc9aUkpjcE.vjiFUorl9JK5GRB74xfSxO04_UWovS_VODmQYNBLoRMnM44ZDzm5OYxM9VMURH9LLm5i_3JQ53i0_qGxTqPq90; path=/; expires=Sat, 03-May-25 03:23:32 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=9LSuGMtnxsWopo_ID.J7KCFtocP_Ufv3ZheC7NvMShk-1746240812710-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'939c77f288a2aaf0-SYD'), (b'alt-svc', b'h3=":443"; ma=86400')])
HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
receive_response_body.started request=<Request [b'POST']>
receive_response_body.complete
response_closed.started
response_closed.complete
HTTP Response: POST https://api.openai.com/v1/chat/completions "429 Too Many Requests" Headers([('date', 'Sat, 03 May 2025 02:53:32 GMT'), ('content-type', 'application/json; charset=utf-8'), ('content-length', '337'), ('connection', 'keep-alive'), ('vary', 'Origin'), ('x-request-id', 'req_9e25847724492041bd686514945f4ee4'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=.FGNEKtXkb4Yl4RfVVHPpsYUpdjM3scYdl3fqGLlR0I-1746240812-1.0.1.1-Ymeu_8fVYDIc9aUkpjcE.vjiFUorl9JK5GRB74xfSxO04_UWovS_VODmQYNBLoRMnM44ZDzm5OYxM9VMURH9LLm5i_3JQ53i0_qGxTqPq90; path=/; expires=Sat, 03-May-25 03:23:32 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=9LSuGMtnxsWopo_ID.J7KCFtocP_Ufv3ZheC7NvMShk-1746240812710-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '939c77f288a2aaf0-SYD'), ('alt-svc', 'h3=":443"; ma=86400')])
request_id: req_9e25847724492041bd686514945f4ee4
Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/site-packages/openai/_base_client.py", line 1014, in request
    response.raise_for_status()
  File "/usr/local/lib/python3.11/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
Retrying due to status code 429
2 retries left
Retrying request to /chat/completions in 0.499300 seconds
Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-9782ea06-a53b-4cac-b221-75b6b61fa33c', 'json_data': {'messages': [{'role': 'user', 'content': 'Hi'}, {'role': 'user', 'content': 'Hi'}], 'model': 'gpt-3.5-turbo', 'max_tokens': 150, 'n': 1, 'response_format': {}, 'stop': None, 'temperature': 0.7}}
Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
send_request_headers.started request=<Request [b'POST']>
send_request_headers.complete
send_request_body.started request=<Request [b'POST']>
send_request_body.complete
receive_response_headers.started request=<Request [b'POST']>
receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Sat, 03 May 2025 02:53:33 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'337'), (b'Connection', b'keep-alive'), (b'vary', b'Origin'), (b'x-request-id', b'req_7a9e4368240b372439288f003d6d83f2'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'939c77fb1f29aaf0-SYD'), (b'alt-svc', b'h3=":443"; ma=86400')])
HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
receive_response_body.started request=<Request [b'POST']>
receive_response_body.complete
response_closed.started
response_closed.complete
HTTP Response: POST https://api.openai.com/v1/chat/completions "429 Too Many Requests" Headers({'date': 'Sat, 03 May 2025 02:53:33 GMT', 'content-type': 'application/json; charset=utf-8', 'content-length': '337', 'connection': 'keep-alive', 'vary': 'Origin', 'x-request-id': 'req_7a9e4368240b372439288f003d6d83f2', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '939c77fb1f29aaf0-SYD', 'alt-svc': 'h3=":443"; ma=86400'})
request_id: req_7a9e4368240b372439288f003d6d83f2
Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/site-packages/openai/_base_client.py", line 1014, in request
    response.raise_for_status()
  File "/usr/local/lib/python3.11/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
Retrying due to status code 429
1 retry left
Retrying request to /chat/completions in 0.938871 seconds
Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-9782ea06-a53b-4cac-b221-75b6b61fa33c', 'json_data': {'messages': [{'role': 'user', 'content': 'Hi'}, {'role': 'user', 'content': 'Hi'}], 'model': 'gpt-3.5-turbo', 'max_tokens': 150, 'n': 1, 'response_format': {}, 'stop': None, 'temperature': 0.7}}
Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
send_request_headers.started request=<Request [b'POST']>
send_request_headers.complete
send_request_body.started request=<Request [b'POST']>
send_request_body.complete
receive_response_headers.started request=<Request [b'POST']>
receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Sat, 03 May 2025 02:53:34 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'337'), (b'Connection', b'keep-alive'), (b'vary', b'Origin'), (b'x-request-id', b'req_7e9ae85a90ec8597fa0e445058e83cf7'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'939c7802eca7aaf0-SYD'), (b'alt-svc', b'h3=":443"; ma=86400')])
HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
receive_response_body.started request=<Request [b'POST']>
receive_response_body.complete
response_closed.started
response_closed.complete
HTTP Response: POST https://api.openai.com/v1/chat/completions "429 Too Many Requests" Headers({'date': 'Sat, 03 May 2025 02:53:34 GMT', 'content-type': 'application/json; charset=utf-8', 'content-length': '337', 'connection': 'keep-alive', 'vary': 'Origin', 'x-request-id': 'req_7e9ae85a90ec8597fa0e445058e83cf7', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '939c7802eca7aaf0-SYD', 'alt-svc': 'h3=":443"; ma=86400'})
request_id: req_7e9ae85a90ec8597fa0e445058e83cf7
Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/site-packages/openai/_base_client.py", line 1014, in request
    response.raise_for_status()
  File "/usr/local/lib/python3.11/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
Re-raising status error
Failed Dependency: /api/support/model/e8dc402b-6bb1-4874-a230-875aa5231d13/test/
Failed Dependency: /api/support/model/e8dc402b-6bb1-4874-a230-875aa5231d13/test/
Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-28a2bb1a-b03c-47ed-b472-d69ebd8908ec', 'json_data': {'messages': [{'role': 'user', 'content': 'Hi'}, {'role': 'user', 'content': 'How you doing'}, {'role': 'user', 'content': 'How you doing'}], 'model': 'gpt-3.5-turbo', 'max_tokens': 150, 'n': 1, 'response_format': {}, 'stop': None, 'temperature': 0.7}}
Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0xffff97c84110>
start_tls.started ssl_context=<ssl.SSLContext object at 0xffff97e04dd0> server_hostname='api.openai.com' timeout=5.0
start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0xffff97c86310>
send_request_headers.started request=<Request [b'POST']>
send_request_headers.complete
send_request_body.started request=<Request [b'POST']>
send_request_body.complete
receive_response_headers.started request=<Request [b'POST']>
receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Sat, 03 May 2025 02:53:40 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'337'), (b'Connection', b'keep-alive'), (b'vary', b'Origin'), (b'x-request-id', b'req_f4bf71015a5e563ee61534e271609857'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=o5T_e0y7d2Ec1ZLoNiI7_KkVTn9Xl_8f8HOmzJzhDeo-1746240820-1.0.1.1-vO18yOjFzj77avn_mHlCdvvz1TjkBi5Kayi1Bj1H_ll5cTyuKPkQCFA7ev.5f51tu.TKPK9VLofHUm0Jb3erFVSOHTxoXuid9Qo0HOQpG9s; path=/; expires=Sat, 03-May-25 03:23:40 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=V7mI7naLuU.ziscGX4ZfqWjVVgikSaM6v0KOOelJBzs-1746240820465-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'939c78268dd5aaf5-SYD'), (b'alt-svc', b'h3=":443"; ma=86400')])
HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
receive_response_body.started request=<Request [b'POST']>
receive_response_body.complete
response_closed.started
response_closed.complete
HTTP Response: POST https://api.openai.com/v1/chat/completions "429 Too Many Requests" Headers([('date', 'Sat, 03 May 2025 02:53:40 GMT'), ('content-type', 'application/json; charset=utf-8'), ('content-length', '337'), ('connection', 'keep-alive'), ('vary', 'Origin'), ('x-request-id', 'req_f4bf71015a5e563ee61534e271609857'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=o5T_e0y7d2Ec1ZLoNiI7_KkVTn9Xl_8f8HOmzJzhDeo-1746240820-1.0.1.1-vO18yOjFzj77avn_mHlCdvvz1TjkBi5Kayi1Bj1H_ll5cTyuKPkQCFA7ev.5f51tu.TKPK9VLofHUm0Jb3erFVSOHTxoXuid9Qo0HOQpG9s; path=/; expires=Sat, 03-May-25 03:23:40 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=V7mI7naLuU.ziscGX4ZfqWjVVgikSaM6v0KOOelJBzs-1746240820465-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '939c78268dd5aaf5-SYD'), ('alt-svc', 'h3=":443"; ma=86400')])
request_id: req_f4bf71015a5e563ee61534e271609857
Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/site-packages/openai/_base_client.py", line 1014, in request
    response.raise_for_status()
  File "/usr/local/lib/python3.11/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
Retrying due to status code 429
2 retries left
Retrying request to /chat/completions in 0.441645 seconds
Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-28a2bb1a-b03c-47ed-b472-d69ebd8908ec', 'json_data': {'messages': [{'role': 'user', 'content': 'Hi'}, {'role': 'user', 'content': 'How you doing'}, {'role': 'user', 'content': 'How you doing'}], 'model': 'gpt-3.5-turbo', 'max_tokens': 150, 'n': 1, 'response_format': {}, 'stop': None, 'temperature': 0.7}}
Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
send_request_headers.started request=<Request [b'POST']>
send_request_headers.complete
send_request_body.started request=<Request [b'POST']>
send_request_body.complete
receive_response_headers.started request=<Request [b'POST']>
receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Sat, 03 May 2025 02:53:41 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'337'), (b'Connection', b'keep-alive'), (b'vary', b'Origin'), (b'x-request-id', b'req_6bd2480773bd5fe6ee17ba47e5ae0a72'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'939c782af8e4aaf5-SYD'), (b'alt-svc', b'h3=":443"; ma=86400')])
HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
receive_response_body.started request=<Request [b'POST']>
receive_response_body.complete
response_closed.started
response_closed.complete
HTTP Response: POST https://api.openai.com/v1/chat/completions "429 Too Many Requests" Headers({'date': 'Sat, 03 May 2025 02:53:41 GMT', 'content-type': 'application/json; charset=utf-8', 'content-length': '337', 'connection': 'keep-alive', 'vary': 'Origin', 'x-request-id': 'req_6bd2480773bd5fe6ee17ba47e5ae0a72', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '939c782af8e4aaf5-SYD', 'alt-svc': 'h3=":443"; ma=86400'})
request_id: req_6bd2480773bd5fe6ee17ba47e5ae0a72
Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/site-packages/openai/_base_client.py", line 1014, in request
    response.raise_for_status()
  File "/usr/local/lib/python3.11/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
Retrying due to status code 429
1 retry left
Retrying request to /chat/completions in 0.805008 seconds
Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-28a2bb1a-b03c-47ed-b472-d69ebd8908ec', 'json_data': {'messages': [{'role': 'user', 'content': 'Hi'}, {'role': 'user', 'content': 'How you doing'}, {'role': 'user', 'content': 'How you doing'}], 'model': 'gpt-3.5-turbo', 'max_tokens': 150, 'n': 1, 'response_format': {}, 'stop': None, 'temperature': 0.7}}
Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
send_request_headers.started request=<Request [b'POST']>
send_request_headers.complete
send_request_body.started request=<Request [b'POST']>
send_request_body.complete
receive_response_headers.started request=<Request [b'POST']>
receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Sat, 03 May 2025 02:53:42 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'337'), (b'Connection', b'keep-alive'), (b'vary', b'Origin'), (b'x-request-id', b'req_4f766f9930821629f41fce6c0fba8857'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'939c78321e84aaf5-SYD'), (b'alt-svc', b'h3=":443"; ma=86400')])
HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
receive_response_body.started request=<Request [b'POST']>
receive_response_body.complete
response_closed.started
response_closed.complete
HTTP Response: POST https://api.openai.com/v1/chat/completions "429 Too Many Requests" Headers({'date': 'Sat, 03 May 2025 02:53:42 GMT', 'content-type': 'application/json; charset=utf-8', 'content-length': '337', 'connection': 'keep-alive', 'vary': 'Origin', 'x-request-id': 'req_4f766f9930821629f41fce6c0fba8857', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '939c78321e84aaf5-SYD', 'alt-svc': 'h3=":443"; ma=86400'})
request_id: req_4f766f9930821629f41fce6c0fba8857
Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/site-packages/openai/_base_client.py", line 1014, in request
    response.raise_for_status()
  File "/usr/local/lib/python3.11/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
Re-raising status error
Failed Dependency: /api/support/model/e8dc402b-6bb1-4874-a230-875aa5231d13/test/
Failed Dependency: /api/support/model/e8dc402b-6bb1-4874-a230-875aa5231d13/test/
close.started
close.complete
close.started
close.complete
Not Found: /
Not Found: /
Not Found: /ws/chat/
Not Found: /ws/chat/
Not Found: /
Not Found: /
Not Found: /ws/chat/
Not Found: /ws/chat/
Not Found: /ws/chat/
Not Found: /ws/chat/
Not Found: /ws/chat/
Not Found: /ws/chat/
Not Found: /ws/chat/
Not Found: /ws/chat/
Not Found: /ws/chat/
Not Found: /ws/chat/
Not Found: /ws/chat/
Not Found: /ws/chat/
Not Found: /ws/chat/
Not Found: /ws/chat/
Not Found: /ws/chat/
Not Found: /ws/chat/
Not Found: /ws/chat/
Not Found: /ws/chat/
Not Found: /ws/chat/
Not Found: /ws/chat/
Not Found: /ws/chat/
Not Found: /ws/chat/
Not Found: /ws/chat/
Not Found: /ws/chat/
Not Found: /ws/chat/
Not Found: /ws/chat/
Not Found: /ws/chat/
Not Found: /ws/chat/
Not Found: /ws/chat/
Not Found: /ws/chat/
